{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import  music21 as ms21\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "midi_predict_path = \"./caption+visual_att_4_midi/\"\n",
    "midi_gt_path = \"./gt_midi/\"\n",
    "\n",
    "midi_predict_files = os.listdir(midi_predict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_midi(path):\n",
    "    s=ms21.converter.parse(path)\n",
    "    note2id = {\n",
    "        \"C\": 0, \n",
    "        \"C#\": 1, \n",
    "        \"D\": 2, \n",
    "        \"E-\": 3, \n",
    "        \"E\": 4, \n",
    "        \"F\": 5, \n",
    "        \"F#\": 6, \n",
    "        \"G\": 7, \n",
    "        \"G#\": 8, \n",
    "        \"A\": 9, \n",
    "        \"B-\": 10,\n",
    "        \"B\": 11, \n",
    "    }\n",
    "\n",
    "    notes, bar, pattern, pattern_bar = [], [], [], [0 for k in range(16)]\n",
    "    lastoffset = 0\n",
    "    i, j = 1, 0\n",
    "\n",
    "    for note in s.flat.notesAndRests:\n",
    "        if isinstance(note, ms21.note.Rest):\n",
    "            continue\n",
    "\n",
    "        if note.offset >= 32 * i and lastoffset < 32 * i:\n",
    "            notes.append(bar)\n",
    "            bar = []\n",
    "            i += 1\n",
    "        while note.offset >= 4 * (j + 1) and lastoffset < 4 * (j + 1):\n",
    "            pattern.append(np.array(pattern_bar))\n",
    "            pattern_bar = [0 for k in range(16)]\n",
    "            j += 1\n",
    "\n",
    "        if isinstance(note,ms21.note.Note):\n",
    "            # print(note.name, note.octave, note.pitch, note.pitch.midi, note.duration.quarterLength)\n",
    "            bar.append(note2id[note.name])\n",
    "            pattern_bar[int(4*(note.offset-4*j))] = 1\n",
    "        else:\n",
    "            try:\n",
    "                for c_note in note.notes:\n",
    "                    # print(c_note.name, c_note.pitch.midi, c_note.duration.quarterLength)\n",
    "                    bar.append(note2id[c_note.name])\n",
    "            except:\n",
    "                pass\n",
    "            pattern_bar[int(4*(note.offset-4*j))] = 1\n",
    "            \n",
    "        lastoffset = note.offset\n",
    "    \n",
    "    return notes, bar, pattern, pattern_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate pitch_class_histogram_entropy (PCHE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pitch_class_histogram_entropy(notes):\n",
    "    \n",
    "    result = []\n",
    "\n",
    "    for bar in notes:\n",
    "        # Construct the 12-dimensional pitch class histogram\n",
    "        histogram = np.zeros(12)\n",
    "        for note in bar:\n",
    "            pitch_class = note % 12\n",
    "            histogram[pitch_class] += 1\n",
    "\n",
    "        # Normalize the histogram\n",
    "        histogram = histogram / np.sum(histogram)\n",
    "\n",
    "        # Calculate the entropy\n",
    "        entropy = -np.sum(histogram * np.log2(histogram + 1e-6))  # Added epsilon to avoid log(0)\n",
    "        result.append(entropy)\n",
    "\n",
    "    return sum(result)/len(notes)\n",
    "\n",
    "pche = []\n",
    "\n",
    "for item in midi_predict_files:\n",
    "# for item in midi_gt_files:\n",
    "\n",
    "    file_path = f'{midi_predict_files}{item}'\n",
    "\n",
    "    notes, bar, pattern, pattern_bar = process_midi(file_path)\n",
    "\n",
    "    pche.append(pitch_class_histogram_entropy(notes))\n",
    "\n",
    "sum(pche) / len(pche)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate grooving_pattern_similarity (GPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grooving_pattern_similarity(g_a, g_b):\n",
    "    assert len(g_a) == len(g_b), \"Grooving patterns must have the same length\"\n",
    "    Q = len(g_a)\n",
    "    gs = 1 - (1/Q) * np.sum(np.bitwise_xor(g_a, g_b))\n",
    "    return gs\n",
    "\n",
    "def cal_cps(pattern):\n",
    "\n",
    "    results = []\n",
    "    for i in range(len(pattern)):\n",
    "        for j in range(i + 1, len(pattern)):\n",
    "            g_a, g_b = pattern[i], pattern[j]\n",
    "            results.append(grooving_pattern_similarity(g_a, g_b))\n",
    "\n",
    "    return sum(results) / len(results)\n",
    "\n",
    "cps = []\n",
    "\n",
    "for item in midi_predict_files:\n",
    "\n",
    "    file_path = f'{midi_predict_path}{item}'\n",
    "\n",
    "    notes, bar, pattern, pattern_bar = process_midi(file_path)\n",
    "\n",
    "    cps.append(cal_cps(pattern))\n",
    "\n",
    "sum(cps) / len(cps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate the video-music correspondence, you should first transfer the midi output into audio, then extract the features and calculate the recall ratio."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. transfer the midi files into audio files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from midi2audio import FluidSynth\n",
    "\n",
    "# You can download the sound file at https://github.com/vyshor/MusicAids/blob/master/default_sound_font.sf2\n",
    "fs = FluidSynth(sound_font=\"./default_sound_font.sf2\")\n",
    "mp3_path = midi_predict_path[:-1]+\"_mp3/\"\n",
    "os.mkdir(mp3_path)\n",
    "\n",
    "ls = os.listdir(midi_predict_path)\n",
    "for i in ls:\n",
    "    idx = i[:3]\n",
    "    fs.midi_to_audio(f\"{midi_predict_path}{idx}.mid\", f\"{mp3_path}{idx}.mp3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. use [Musicnn](https://github.com/jordipons/musicnn) to extract the audio features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. process the features to calculate the recall ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "import numpy as np\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "length = 1e9\n",
    "\n",
    "# You can get our processed feature at https://drive.google.com/drive/folders/1sOLV2HtmXVwRLerw6Bt5W0UHhBreJ1-0?usp=sharing\n",
    "gt_path = \"./gt_feats/\"\n",
    "gt_files = os.listdir(gt_path)\n",
    "gt_feats = []\n",
    "\n",
    "# You can get our processed feature at https://drive.google.com/drive/folders/1vRWGxsg3KxJ5vSjX-jaDf1FlyhWez2SV?usp=sharing\n",
    "predict_path_feats = \"./caption+visual_att_4_feats/\"\n",
    "predict_files_feats = os.listdir(predict_path_feats)\n",
    "predict_feats = []\n",
    "\n",
    "for item in gt_files:\n",
    "    if item in predict_files_feats:\n",
    "        feat_gt = np.load(f'{gt_path}{item}')\n",
    "        feat_predict = np.load(f'{predict_path_feats}{item}')\n",
    "        for i in range(min(feat_gt.shape[0], feat_predict.shape[0])):\n",
    "            gt_feats.append(feat_gt[i, :])\n",
    "            predict_feats.append(feat_predict[i, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating Recall...\n",
      "Recall@1: 0.038788522848034\n",
      "Recall@2: 0.06854410201912858\n",
      "Recall@3: 0.10361317747077577\n",
      "Recall@5: 0.15993623804463336\n",
      "Recall@10: 0.2688629117959617\n",
      "Recall@20: 0.4691817215727949\n",
      "AP: 24.44155154091392\n"
     ]
    }
   ],
   "source": [
    "from scipy import spatial\n",
    "from random import sample\n",
    "\n",
    "print(\"Calculating Recall...\")\n",
    "acc = {\n",
    "    \"1\": 0, \n",
    "    \"2\": 0, \n",
    "    \"3\": 0, \n",
    "    \"5\": 0, \n",
    "    \"10\": 0, \n",
    "    \"20\": 0, \n",
    "}\n",
    "idx_record = []\n",
    "\n",
    "for i, item in enumerate(predict_feats):\n",
    "    sim = []\n",
    "\n",
    "    select_gt_feats = []\n",
    "    ls = [j for j in range(500)]\n",
    "    idx_ls = sample(ls, 60)\n",
    "    if not i in idx_ls:\n",
    "        idx_ls[0] = i\n",
    "    ans = idx_ls.index(i)\n",
    "    for j in idx_ls:\n",
    "        select_gt_feats.append(gt_feats[j])\n",
    "\n",
    "    for item_gt in select_gt_feats:\n",
    "        cos_sim = 1 - spatial.distance.cosine(item, item_gt)\n",
    "        sim.append(cos_sim)\n",
    "    max_index = sorted(range(len(sim)), key=lambda x: -sim[x])\n",
    "    for k in acc.keys():\n",
    "        if ans in max_index[:int(k)]:\n",
    "            acc[k] += 1\n",
    "    idx_record.append(max_index.index(ans)+1)\n",
    "\n",
    "for k in acc.keys():\n",
    "    print(f\"Recall@{k}: {acc[k]/len(predict_feats)}\")\n",
    "print(f\"AP: {sum(idx_record)/len(idx_record)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
